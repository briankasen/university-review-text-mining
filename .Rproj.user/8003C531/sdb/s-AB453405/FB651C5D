{
    "collab_server" : "",
    "contents" : "library(tm)\n\n#Create Corpus\ndocs <- Corpus(DirSource(\"/Users/briankasen/Dropbox/MRKT 845 Advanced Marketing Analytics/4. Text Mining/TextMining/\"))\n\ndocs\n\n#inspect a particular document\nwriteLines(as.character(docs[[30]]))\n\n# view all transformations from the tm package\ngetTransformations()\n\n# create the toSpace content transformer\ntoSpace <- content_transformer(function(x, pattern) {return (gsub(pattern, \" \", x))})\n\ndocs <- tm_map(docs, toSpace, \"-\")\ndocs <- tm_map(docs, toSpace, \":\")\n\n# inspect transformations\nwriteLines(as.character(docs[[30]]))\n\n# Remove punctuation – replace punctuation marks with ” “\ndocs <- tm_map(docs, removePunctuation)\n\n# inspect transformations\nwriteLines(as.character(docs[[30]]))\n\n# Remove non-standard punctuation\ndocs <- tm_map(docs, toSpace, \"’\")\ndocs <- tm_map(docs, toSpace, \"‘\")\ndocs <- tm_map(docs, toSpace, \" -\")\n\n# inspect transformations\nwriteLines(as.character(docs[[30]]))\nwriteLines(as.character(docs[[29]]))\n\n# Remove addt'l punctuation and special symbols\n\nwriteLines(as.character(docs[[30]]))\nwriteLines(as.character(docs[[25]]))\n\n#Transform to lower case (need to wrap in content_transformer)\ndocs <- tm_map(docs,content_transformer(tolower))\n\n#Strip digits (std transformation, so no need for content_transformer)\ndocs <- tm_map(docs, removeNumbers)\n\nwriteLines(as.character(docs[[30]]))\n\n#remove stopwords using the standard list in tm\ndocs <- tm_map(docs, removeWords, stopwords(\"english\"))\ndocs <- tm_map(docs, removeWords, c(\"like\", \"also\", \"said\", \"often\", \"say\", \"get\", \"say\", \"can\", \"see\"))\n\nwriteLines(as.character(docs[[30]]))\n\n#Strip whitespace (cosmetic?)\ndocs <- tm_map(docs, stripWhitespace)\nwriteLines(as.character(docs[[30]]))\n\n#load library\nlibrary(SnowballC)\n#Stem document\ndocs <- tm_map(docs,stemDocument)\nwriteLines(as.character(docs[[30]]))\n\n\ndocs <- tm_map(docs, content_transformer(gsub), pattern = \"organiz\", replacement = \"organ\")\ndocs <- tm_map(docs, content_transformer(gsub), pattern = \"organis\", replacement = \"organ\")\ndocs <- tm_map(docs, content_transformer(gsub), pattern = \"andgovern\", replacement = \"govern\")\ndocs <- tm_map(docs, content_transformer(gsub), pattern = \"inenterpris\", replacement = \"enterpris\")\ndocs <- tm_map(docs, content_transformer(gsub), pattern = \"team-\", replacement = \"team\")\n\nwriteLines(as.character(docs[[28]]))\n\n# Build a Document Term Matrix\ndtm <- DocumentTermMatrix(docs)\n\ndtm\n\n# inspect a small portion of the dtm\ninspect(dtm[1:2,1000:1005])\n\n# get frequency of words in the corpus\nfreq <- colSums(as.matrix(dtm))\nfreq\n\n#length should be total number of terms\nlength(freq)\n\n# create sort order (descending)\nord <- order(freq,decreasing=TRUE)\nord\n\n#inspect most frequently occurring terms\nfreq[head(ord)]\n\n#inspect least frequently occurring terms\nfreq[tail(ord)]\n\n# Here we have told R to include only those words that occur in  3 to 27 documents\n# We have also enforced  lower and upper limit to length of the words included (between 4 and 20 characters)\ndtmr <-DocumentTermMatrix(docs, control=list(wordLengths=c(4, 20), bounds = list(global = c(3,27))))\ndtmr\n\nfreqr <- colSums(as.matrix(dtmr))\n#length should be total number of terms\nlength(freqr)\n\n#create sort order (asc)\nordr <- order(freqr,decreasing=TRUE)\n#inspect most frequently occurring terms\nfreqr[head(ordr)]\n#inspect least frequently occurring terms\nfreqr[tail(ordr)]\n\n# let’s take get a list of terms that occur at least a  100 times in the entire corpus\nfindFreqTerms(dtmr,lowfreq=80)\n\n# term correlations: correlation is a quantitative measure of the co-occurrence of words in multiple documents\nfindAssocs(dtmr,\"project\",0.6)\nfindAssocs(dtmr,\"enterpris\",0.6)\nfindAssocs(dtmr,\"system\",0.6)\n\n\n# Visualizations\nwf=data.frame(term=names(freqr),occurrences=freqr)\nlibrary(ggplot2)\np <- ggplot(subset(wf, freqr>100), aes(term, occurrences))\np <- p + geom_bar(stat=\"identity\")\np <- p + theme(axis.text.x=element_text(angle=45, hjust=1))\np\n\n#wordcloud\nlibrary(wordcloud)\n#setting the same seed each time ensures consistent look across clouds\nset.seed(42)\n#limit words by specifying min frequency\nwordcloud(names(freqr),freqr, min.freq=70)\n#…add color\nwordcloud(names(freqr),freqr,min.freq=70,colors=brewer.pal(6,\"Dark2\"))\n",
    "created" : 1517520205029.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "106677112",
    "id" : "FB651C5D",
    "lastKnownWriteTime" : 1516767192,
    "last_content_update" : 1516767192,
    "path" : "~/Dropbox/MRKT 845 Advanced Marketing Analytics/4. Text Mining/TextMining Example Script.R",
    "project_path" : null,
    "properties" : {
    },
    "relative_order" : 2,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}