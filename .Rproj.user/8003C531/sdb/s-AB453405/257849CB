{
    "collab_server" : "",
    "contents" : "library(tm)\n\n\n\n#Create Corpus\ndocs <- Corpus(DirSource(\"reviews/\"))\ndocs_orig <- docs\ndocs\n\n\n#inspect a particular document\nwriteLines(as.character(docs[[30]]))\n\n# create the toSpace content transformer\ntoSpace <- content_transformer(function(x, pattern) {return (gsub(pattern, \" \", x))})\n\ndocs <- tm_map(docs, toSpace, \"-\")\ndocs <- tm_map(docs, toSpace, \":\")\n\n# Remove punctuation – replace punctuation marks with ” “\ndocs <- tm_map(docs, removePunctuation)\n\n# Remove non-standard punctuation\ndocs <- tm_map(docs, toSpace, \"’\")\ndocs <- tm_map(docs, toSpace, \"‘\")\ndocs <- tm_map(docs, toSpace, \" -\")\n\n#view printout of many documents at one time to inspect\nstrwrap(docs[1:5])\n\n#Transform to lower case (need to wrap in content_transformer)\ndocs <- tm_map(docs,content_transformer(tolower))\n\n#Strip digits (std transformation, so no need for content_transformer)\ndocs <- tm_map(docs, removeNumbers)\n\nwriteLines(as.character(docs[[30]]))\n\ndocs <- tm_map(docs, content_transformer(gsub), pattern = \"on campus\", replacement = \"oncampus\")\ndocs <- tm_map(docs, content_transformer(gsub), pattern = \"off campus\", replacement = \"offcampus\")\n\n\n#remove stopwords using the standard list in tm\n# placed the removal of general stopwords after removal of university names which used stopwords\ndocs_w_stop_words <- docs\ndocs <- tm_map(docs, removeWords, stopwords(\"english\"))\nstrwrap(docs[1:5])\n\nwriteLines(as.character(docs[[30]]))\n\ndocs <- tm_map(docs, removeWords, c(\"like\", \"itll\", \"youre\", \"also\", \"said\", \"even\", \"though\", \"often\", \"go\", \"theres\", \"just\", \"say\", \"get\", \"say\", \"can\", \"see\", \"will\", \"one\"))\n\n\n\n#view printout of many documents at one time to inspect\nstrwrap(docs[1])\n\n#load library\nlibrary(SnowballC)\n#Stem document\n# docs <- tm_map(docs,stemDocument)\nwriteLines(as.character(docs[[30]]))\n\ndocs <- tm_map(docs, content_transformer(gsub), pattern = \"professorprofess\", replacement = \"professor\")\ndocs <- tm_map(docs, content_transformer(gsub), pattern = \"professs\", replacement = \"professor\")\ndocs <- tm_map(docs, content_transformer(gsub), pattern = \"professorta\", replacement = \"professor\")\ndocs <- tm_map(docs, content_transformer(gsub), pattern = \"professorta\", replacement = \"professor\")\ndocs <- tm_map(docs, content_transformer(gsub), pattern = \"professors\", replacement = \"professor\")\ndocs <- tm_map(docs, content_transformer(gsub), pattern = \"students\", replacement = \"student\")\ndocs <- tm_map(docs, content_transformer(gsub), pattern = \"sciences\", replacement = \"science\")\n\ndocs <- tm_map(docs, content_transformer(gsub), pattern = \"exams\", replacement = \"science\")\n\ndocs <- tm_map(docs, content_transformer(gsub), pattern = \" campus beautiful \", replacement = \" beatiful campus \")\ndocs <- tm_map(docs, content_transformer(gsub), pattern = \" great school \", replacement = \" \")\n\n\ndocs <- tm_map(docs, content_transformer(gsub), pattern = \"succeed\", replacement = \"success\")\ndocs <- tm_map(docs, content_transformer(gsub), pattern = \" university \", replacement = \" \")\ndocs <- tm_map(docs, content_transformer(gsub), pattern = \" northwestern \", replacement = \" \")\ndocs <- tm_map(docs, content_transformer(gsub), pattern = \" michigan \", replacement = \" \")\ndocs <- tm_map(docs, content_transformer(gsub), pattern = \" ann arbor \", replacement = \" \")\ndocs <- tm_map(docs, content_transformer(gsub), pattern = \" wisconsin \", replacement = \" \")\ndocs <- tm_map(docs, content_transformer(gsub), pattern = \" madison \", replacement = \" \")\ndocs <- tm_map(docs, content_transformer(gsub), pattern = \" illinois \", replacement = \" \")\ndocs <- tm_map(docs, content_transformer(gsub), pattern = \" urbana \", replacement = \" \")\ndocs <- tm_map(docs, content_transformer(gsub), pattern = \" champaign \", replacement = \" \")\ndocs <- tm_map(docs, content_transformer(gsub), pattern = \" uiuc \", replacement = \" \")\ndocs <- tm_map(docs, content_transformer(gsub), pattern = \" purdue \", replacement = \" \")\ndocs <- tm_map(docs, content_transformer(gsub), pattern = \" purdues \", replacement = \" \")\ndocs <- tm_map(docs, content_transformer(gsub), pattern = \" penn \", replacement = \" \")\ndocs <- tm_map(docs, content_transformer(gsub), pattern = \" penn state \", replacement = \" \")\ndocs <- tm_map(docs, content_transformer(gsub), pattern = \" ohio \", replacement = \" \")\ndocs <- tm_map(docs, content_transformer(gsub), pattern = \" ohio state \", replacement = \" \")\ndocs <- tm_map(docs, content_transformer(gsub), pattern = \" columbus \", replacement = \" \")\ndocs <- tm_map(docs, content_transformer(gsub), pattern = \" minnesota \", replacement = \" \")\ndocs <- tm_map(docs, content_transformer(gsub), pattern = \" twin cities \", replacement = \" \")\ndocs <- tm_map(docs, content_transformer(gsub), pattern = \" maryland \", replacement = \" \")\ndocs <- tm_map(docs, content_transformer(gsub), pattern = \" college park \", replacement = \" \")\ndocs <- tm_map(docs, content_transformer(gsub), pattern = \" indiana \", replacement = \" \")\ndocs <- tm_map(docs, content_transformer(gsub), pattern = \" bloomington \", replacement = \" \")\ndocs <- tm_map(docs, content_transformer(gsub), pattern = \" iowa \", replacement = \" \")\ndocs <- tm_map(docs, content_transformer(gsub), pattern = \" iowa city \", replacement = \" \")\ndocs <- tm_map(docs, content_transformer(gsub), pattern = \" rutgers \", replacement = \" \")\ndocs <- tm_map(docs, content_transformer(gsub), pattern = \" new brunswick \", replacement = \" \")\ndocs <- tm_map(docs, content_transformer(gsub), pattern = \" nebraska \", replacement = \" \")\ndocs <- tm_map(docs, content_transformer(gsub), pattern = \" lincoln \", replacement = \" \")\n\ndocs <- tm_map(docs, content_transformer(gsub), pattern = \"illini\", replacement = \" \")\ndocs <- tm_map(docs, content_transformer(gsub), pattern = \"spartan\", replacement = \" \")\ndocs <- tm_map(docs, content_transformer(gsub), pattern = \"badger\", replacement = \" \")\ndocs <- tm_map(docs, content_transformer(gsub), pattern = \"husker\", replacement = \" \")\ndocs <- tm_map(docs, content_transformer(gsub), pattern = \"buckeye\", replacement = \" \")\ndocs <- tm_map(docs, content_transformer(gsub), pattern = \"bucks\", replacement = \" \")\ndocs <- tm_map(docs, content_transformer(gsub), pattern = \"boiler\", replacement = \" \")\ndocs <- tm_map(docs, content_transformer(gsub), pattern = \"boilermaker\", replacement = \" \")\ndocs <- tm_map(docs, content_transformer(gsub), pattern = \"hoosier\", replacement = \" \")\ndocs <- tm_map(docs, content_transformer(gsub), pattern = \"blue\", replacement = \" \")\n\ndocs <- tm_map(docs, content_transformer(gsub), pattern = \" u \", replacement = \" \")\ndocs <- tm_map(docs, content_transformer(gsub), pattern = \" i \", replacement = \" \")\ndocs <- tm_map(docs, content_transformer(gsub), pattern = \" m \", replacement = \" \")\ndocs <- tm_map(docs, content_transformer(gsub), pattern = \" w \", replacement = \" \")\n\ndocs <- tm_map(docs, content_transformer(gsub), pattern = \" iu \", replacement = \" \")\ndocs <- tm_map(docs, content_transformer(gsub), pattern = \" unl \", replacement = \" \")\ndocs <- tm_map(docs, content_transformer(gsub), pattern = \" msu \", replacement = \" \")\ndocs <- tm_map(docs, content_transformer(gsub), pattern = \" umn \", replacement = \" \")\ndocs <- tm_map(docs, content_transformer(gsub), pattern = \" umd \", replacement = \" \")\n\ndocs <- tm_map(docs, content_transformer(gsub), pattern = \" uw \", replacement = \" \")\ndocs <- tm_map(docs, content_transformer(gsub), pattern = \" osu \", replacement = \" \")\ndocs <- tm_map(docs, content_transformer(gsub), pattern = \" um \", replacement = \" \")\n\ndocs <- tm_map(docs, content_transformer(gsub), pattern = \" don t \", replacement = \" \")\n\n\nstrwrap(docs[1])\n\n\nwriteLines(as.character(docs[[29]]))\nwriteLines(as.character(docs_orig[[28]]))\n\n# Build a Document Term Matrix\ndtm <- DocumentTermMatrix(docs)\n\ndtm\n\n# inspect a small portion of the dtm\ninspect(dtm[1:2,1000:1005])\n\n# get frequency of words in the corpus\nfreq <- colSums(as.matrix(dtm))\n# freq\n\n#length should be total number of terms\nlength(freq)\n\n# create sort order (descending)\nord <- order(freq,decreasing=TRUE)\nord\n\n#inspect most frequently occurring terms\nfreq[head(ord)]\n\n#inspect least frequently occurring terms\nfreq[tail(ord)]\n\n# define threshold variables so they can be used for the aggregate dtm and the institution dtms further down in the script\ndtm_minimum_word_length = 3\ndtm_maximum_word_length = 50\ndtm_minimum_doc_frequency = 3\ndtm_maximum_doc_frequency = 700\n\n# Here we have told R to include only those words that within our doc frequency thresholds\n# We have also enforced  lower and upper limit to length of the words included (between 3 and 50 characters)\ndtmr <-DocumentTermMatrix(docs, control=list(wordLengths=c(dtm_minimum_word_length, dtm_maximum_word_length), bounds = list(global = c(dtm_minimum_doc_frequency,dtm_maximum_doc_frequency))))\ndtmr\n\nfreqr <- colSums(as.matrix(dtmr))\n#length should be total number of terms\nlength(freqr)\n\n#create sort order (asc)\nordr <- order(freqr,decreasing=TRUE)\n#inspect most frequently occurring terms\nfreqr[head(ordr)]\n#inspect least frequently occurring terms\nfreqr[tail(ordr)]\n\n# let’s take get a list of terms that occur at least a  100 times in the entire corpus\nfindFreqTerms(dtmr,lowfreq=100)\n\n# term correlations: correlation is a quantitative measure of the co-occurrence of words in multiple documents\ncorrelation_threshold <- .1\nfindAssocs(dtmr,\"northwesternuniversity\",correlation_threshold)\nfindAssocs(dtmr,\"universityofmichiganannarbor\",correlation_threshold)\nfindAssocs(dtmr,\"universityofwisconsinmadison\",correlation_threshold)\nfindAssocs(dtmr,\"universityofillinoisaturbanachampaign\",correlation_threshold)\nfindAssocs(dtmr,\"purdueuniversity\",correlation_threshold)\nfindAssocs(dtmr,\"pennsylvaniastateuniversity\",correlation_threshold)\nfindAssocs(dtmr,\"ohiostateuniversity\",correlation_threshold)\nfindAssocs(dtmr,\"universityofminnesotatwincities\",correlation_threshold)\nfindAssocs(dtmr,\"michiganstateuniversity\",correlation_threshold)\nfindAssocs(dtmr,\"universityofmarylandcollegepark\",correlation_threshold)\nfindAssocs(dtmr,\"indianauniversitybloomington\",correlation_threshold)\nfindAssocs(dtmr,\"universityofiowa\",correlation_threshold)\nfindAssocs(dtmr,\"rutgersuniversitynewbrunswick\",correlation_threshold)\nfindAssocs(dtmr,\"universityofnebraskalincoln\",correlation_threshold)\n\n\n\n# Build a Document Term Matrix\ninstitution_dtm <- DocumentTermMatrix(docs)\n\ninstitution_dtm\n# create plot of top ten most used words\ninstitution_dtm.matrix <- as.matrix(institution_dtm)\nwordcount <- colSums(institution_dtm.matrix)\ntopten <- head(sort(wordcount, decreasing=TRUE), 10)\ntoptwenty <- head(sort(wordcount, decreasing=TRUE), 15)\n\ntopten\ntoptwenty\n\nlibrary(reshape2)\nlibrary(ggplot2)\n\ndfplot <- as.data.frame(melt(topten))\ndfplot$word <- dimnames(dfplot)[[1]]\ndfplot$word <- factor(dfplot$word, levels=dfplot$word[order(dfplot$value,decreasing=TRUE)])\n\nfig <- ggplot(dfplot, aes(x=word, y=value)) + geom_bar(stat=\"identity\")\nfig <- fig + xlab(\"Word in Corpus\")\nfig <- fig + ylab(\"Count\")\nprint(fig)\n\nlibrary(ngram)\nn_count = 4\ninstitutions_vector = c('northwesternuniversity','universityofmichiganannarbor','universityofwisconsinmadison','universityofillinoisaturbanachampaign','purdueuniversity','pennsylvaniastateuniversity','ohiostateuniversity','universityofminnesotatwincities','michiganstateuniversity','universityofmarylandcollegepark','indianauniversitybloomington','universityofiowa','rutgersuniversitynewbrunswick','universityofnebraskalincoln')\nfor( i in 1:length(institutions_vector)) {\n  for( current_n in 2:n_count) {\n    # print(paste(\"--- Begin N-Gram Analysis (n=\", n_count, \") for \", institutions_vector[i], \" --- \"))\n    \n    # subset corpus to create a smaller corpus of just nebraska reviews\n    institution_corpus <-\n      tm_filter(docs, function(x)\n        any(grep(institutions_vector[i], x, fixed = TRUE)))\n    # strip institution id out of corpus since we know what institution we are doing n-gram analysis on to prevent institution name from showing up in results\n    institution_corpus <-\n      tm_map(\n        institution_corpus,\n        content_transformer(gsub),\n        pattern = institutions_vector[i],\n        replacement = \" \"\n      )\n    \n    \n    \n    \n    # view first row in reduced corpus\n    # strwrap(institution_corpus[1])\n    # print(paste(\"--- Begin N-Gram Analysis (n = \", current_n , \") for \",  institutions_vector[i], \" --- \"))\n    # create ngram object\n    institution_ng <-\n      ngram(concatenate(lapply(institution_corpus, \"[\", 1)), n = current_n)\n    \n    # print truncated view of top n-grams\n    # print(institution_ng, output=\"truncated\")\n    # print top 5 phrasetable n-grams found in university reviews\n    # print(head(get.phrasetable(institution_ng), 5))\n    \n    # print(paste(\"--- End N-Gram Analysis (n = \", current_n , \") for \", institutions_vector[i], \" --- \"))\n    # End N-Gram Analyis\n    \n    \n    institution_corpus <- tm_map(institution_corpus, removeWords, c(\"huge\", \"absolutely\", \"definitely\", \"organizations\", \"community\", \"know\", \"new\", \"better\", \"everything\", \"staff\", \"friendly\", \"met\", \"meet\", \"sports\", \"resources\", \"opportunity\", \"beautiful\", \"academically\", \"known\", \"learn\", \"learning\", \"school\", \"schools\", \"activities\", \"around\", \"offer\", \"offers\", \"plenty\", \"anyone\", \"someone\", \"may\", \"much\", \"extremely\", \"however\", \"able\", \"way\", \"nice\", \"dont\", \"come\", \"enough\", \"makes\", \"year\", \"hard\", \"made\", \"make\", \"things\", \"want\", \"think\", \"different\", \"education\", \"overall\", \"lot\", \"lots\", \"help\", \"world\", \"friends\", \"every\", \"large\", \"involved\", \"club\", \"clubs\", \"home\", \"amazing\", \"time\", \"everyone\", \"time\", \"ive\", \"experience\", \"really\", \"something\", \"life\", \"best\", \"find\", \"feel\", \"major\", \"classes\", \"big\", \"good\", \"class\", \"first\", \"going\", \"well\", \"academic\", \"academics\", \"oncampus\", \"opportunities\", \"student\", \"campus\", \"school\", \"people\", \"great\", \"many\", \"college\", \"always\", \"state\", \"love\", \"place\", \"professor\", \"great\"))\n    \n    # Here we have told R to include only those words that occur in  3 to 27 documents\n    # We have also enforced  lower and upper limit to length of the words included (between 4 and 20 characters)\n    institution_dtmr <-\n      DocumentTermMatrix(institution_corpus, control = list(wordLengths = c(dtm_minimum_word_length, dtm_maximum_word_length), bounds = list(global = c(dtm_minimum_doc_frequency, dtm_maximum_doc_frequency))))\n    # institution_dtmr\n    \n    # get frequency of words in the corpus\n    freq <- colSums(as.matrix(institution_dtmr))\n    # freq\n    \n    #length should be total number of terms\n    # length(freq)\n    \n    # create sort order (descending)\n    institution_ord <- order(freq, decreasing = TRUE)\n    # institution_ord\n    \n    institution_freqr <- colSums(as.matrix(institution_dtmr))\n    #length should be total number of terms\n    # length(institution_freqr)\n    \n    \n    institution_dtm.matrix <- as.matrix(institution_dtmr)\n    wordcount <- colSums(institution_dtm.matrix)\n    toptwenty <- head(sort(wordcount, decreasing=TRUE), 20)\n    print(paste('--- Most Common Terms for ', institutions_vector[i], \" --- \"))\n    if(current_n == 2){\n      print(toptwenty)\n    }\n    \n    #wordcloud\n    library(wordcloud)\n    #setting the same seed each time ensures consistent look across clouds\n    # set.seed(42)\n    # layout(matrix(c(1, 2), nrow = 2), heights = c(1, 4))\n    # par(mar = rep(0, 4))\n    # plot.new()\n    # text(x = 0.5, y = 0.5, institutions_vector[i])\n    # \n    # color wordcloud with 10 or more occurances within the instituion's dtm\n    # wordcloud(\n    #   names(institution_freqr),\n    #   institution_freqr,\n    #   min.freq = 10,\n    #   colors = brewer.pal(6, 'Dark2'),\n    #   main = 'Title'\n    # )\n    # \n    # color wordcloud with 2 or more occurances within the instituion's ngram\n    # layout(matrix(c(1, 2), nrow = 2), heights = c(1, 4))\n    # par(mar = rep(0, 4))\n    # plot.new()\n    # text(x = 0.5, y = 0.5, institutions_vector[i])\n    # wordcloud(\n    #   get.phrasetable(institution_ng)$ngram,\n    #   get.phrasetable(institution_ng)$freq,\n    #   min.freq = 2,\n    #   max.words = 25,\n    #   random.order = F,\n    #   colors = brewer.pal(6, 'Dark2'),\n    #   main = 'Title'\n    # )\n    \n  }\n}\n",
    "created" : 1518372717986.000,
    "dirty" : true,
    "encoding" : "",
    "folds" : "",
    "hash" : "211203267",
    "id" : "257849CB",
    "lastKnownWriteTime" : 1518371871,
    "last_content_update" : 1518372720353,
    "path" : null,
    "project_path" : null,
    "properties" : {
        "tempName" : "Untitled1"
    },
    "relative_order" : 4,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}