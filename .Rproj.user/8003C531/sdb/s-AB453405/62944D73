{
    "collab_server" : "",
    "contents" : "# This code in the language R is an example of doing project 1 for MRKT 845\n# The goal of this project is to build a predictive algorithm for a continuous variable and show that it is \n# a stable model – ie that it still fits reasonably well when applied to a hold-out sample or “test sample.”\n# FIRST TASK: get the data from a csv file and put it into a data frame, then randomly split the\n# data frame into two files about 60/40 – the training data and the test data.\n# reading in the WWW master customer file sample and getting summary stats\n# Read the “Our Imaginary Enterprise” document and confirm its class as data frame,\n# and show the summary of all variables\n# find the Master Customer File for WWW in the filelist on Canvas and read it in below.\nmcf<- read.csv('mcf for project 1.csv',header=TRUE,stringsAsFactors=FALSE) \nclass(mcf)\nsummary(mcf)\n# set seed to keep the partitioning of the data the same for latter runs\nset.seed(10)\n# Split the MCF into a training dataset and a test data set.\ndt = sort(sample(nrow(mcf), nrow(mcf)*.6))\ntrain<-mcf[dt,]\ntest<-mcf[-dt,]\nnrow(train)\nnrow(test)\nhead(train)\nhead(test)\nsummary(train)\nsummary(test)\n# Test correlations of training data\nlibrary(Hmisc)\n# Correlation matrix\ncorr_x_train <- train[1:25]\ncorr_y_train <- train[18]\ncor(corr_x_train, corr_y_train)\n# test correlations of test data\ncorr_x_test <- test[1:25]\ncorr_y_test <- test[18]\ncor(corr_x_test, corr_y_test)\n# drop variables with opposite signs - conclude the direction is due to sampling and not indicative of signficance\n# results comparing the train & test datasets indicate all but the EDUC variable should be allowed inclusion in the NN model build\n# convert the training dataset variables (columns) into variables that are scaled from 0 to 1\nmaxima <- apply(train, 2, max)\nminima <-apply(train, 2, min)\ntrains <- scale(train, center=minima, scale=maxima-minima)\ntrainsdf <- as.data.frame(trains, col.names=colnames(trains))\nsummary(trainsdf)\n# convert the test dataset variables (columns) into variables that are scaled from 0 to 1\nmaxima <- apply(test, 2, max)\nminima <-apply(test, 2, min)\ntests <- scale(test, center=minima, scale=maxima-minima)\ntestsdf <- as.data.frame(tests, col.names=colnames(tests))\nsummary(testsdf)\nfull_lm_results <- lm(TOTCPROF ~ AGE + SEX + INCOME+ KIDHOME+ TEENHOME+ GOURMAGS+ WINEMAGS+ STYLMAGS+ HOUSMAGS+ SPRTMAGS+ TRAVMAGS+ CULTMAGS+ COMPMAGS+ FIRSTPUR+ LASTPUR+ LTV + PCTWEB+ PERCDR+ PERCSR+ PERCDW+ PERCSW+ PERCEX, data=trainsdf)\nsummary(full_lm_results)\nstep_lm_results <- step(full_lm_results, data=trainsdf, direction=\"both\")\nsummary(step_lm_results)\n# stepwise linear model suggested AGE, TEENHOME, GOURMAGS, SPRTMAGS,FIRSTPUR,LTV,PCTWEB,PERCSR are statistically signficant\n# try a neural net on the training data set and keep trying different number of hidden nodes\n# and even number of hidden layers until you get convergence.\n# You may have to click on the “packages” tab in the lower right box, and then the\n# “install” tab and specify the neuralnet package in the dialog box in order to get the \n# neuralnet package.\nlibrary(neuralnet)\nlibrary(plyr)\ntotal_nodes<- 20\ntotal_layers <- 2\nrms_train_results_m <- matrix( c(0), nrow=total_layers, ncol=total_nodes, byrow = TRUE)    \nrms_test_results_m <- matrix( c(0), nrow=total_layers, ncol=total_nodes, byrow = TRUE)    \nrms_train_pass_test_m <- matrix( c(FALSE), nrow=total_layers, ncol=total_nodes, byrow = TRUE)    \nrms_test_pass_test_m <- matrix( c(FALSE), nrow=total_layers, ncol=total_nodes, byrow = TRUE)    \nprogress_bar <- create_progress_bar('text')\nprogress_bar$init(total_nodes*total_layers)\nfor( l in 1:total_layers) {\n  for(n in 1:total_nodes) {\n    print(paste(\"Building NN (layer = \", l, \", nodes = \", n, \")...\"))\n    \n    # tested of reduced variableset NN which did not provide a more accurate model than using the full variable set\n    # nresults <- neuralnet(TOTCPROF ~ AGE+ TEENHOME+ GOURMAGS+ SPRTMAGS+ FIRSTPUR+ LTV + PCTWEB+ PERCSR, trainsdf, hidden=c(n, l), stepmax=80000, threshold=0.08)\n    \n    nresults <- neuralnet(TOTCPROF ~ AGE + SEX + INCOME+ KIDHOME+ TEENHOME+ GOURMAGS+ WINEMAGS+ STYLMAGS+ HOUSMAGS+ SPRTMAGS+ TRAVMAGS+ CULTMAGS+ COMPMAGS+ FIRSTPUR+ LASTPUR+ LTV + PCTWEB+ PERCDR+ PERCSR+ PERCDW+ PERCSW+ PERCEX, trainsdf, hidden=c(n, l), stepmax=80000, threshold=0.08)\n    summary(nresults)   #What things are inside the results object?\n    trainp<- nresults$net.result     #assign the predictions of the dependent variable to an object\n    trainp<-as.data.frame(trainp)   #turn the 12000 x 1 column vector into a data frame\n    class(trainp)\n    names(trainp)[1]<-paste(\"PRED\")   # name the prediction variable \n    head(trainp)\n    # This section merges the training data frame with the predictions of the dependent variable\n    tds<-as.matrix(trainsdf)\n    trs<-as.matrix(trainp)\n    mcfp<-cbind(tds,trs)   # the cbind functions merges two matrices by columns\n    # Now, calculate root-mean-square error of the predictions made by the neural net\n    mcfpdf<-as.data.frame(mcfp)  # convert the merged training portion of the master customer file to a df\n    mcfpdf$d2 <- (mcfpdf$TOTCPROF-mcfpdf$PRED)^2  # calculate the squared difference between the actual\n    #                                                                                  dependent variable and the prediction\n    tail(mcfpdf)\n    rmstrain <- sqrt(mean(mcfpdf$d2))    \n    rmstrain                           # rmstrain is the root-mean squared error\n    rms_train_results_m[l,n] <- rmstrain\n    # for the training data set\n    # Now, determine the root-mean square error for the test data set when applying the neural\n    # net solution that was developed on the training data set. That is, does the neural net solution\n    # developed on the training data set \n    testresults <- subset(testsdf, select=c(AGE, SEX, INCOME,KIDHOME,TEENHOME,GOURMAGS,WINEMAGS,STYLMAGS,HOUSMAGS,SPRTMAGS,TRAVMAGS,CULTMAGS,COMPMAGS,FIRSTPUR,LASTPUR,LTV,PCTWEB,PERCDR,PERCSR,PERCDW,PERCSW,PERCEX))\n    # tested of reduced variable set NN which did not provide a more accurate model than using the full variable set\n    # testresults <- subset(testsdf, select=c(AGE,TEENHOME,GOURMAGS,SPRTMAGS,FIRSTPUR,LTV,PCTWEB,PERCSR))\n    testr <- compute(nresults,testresults)\n    testsdf$PRED<- testr$net.result     #assign the predictions of the dependent variable to a variable \n    #                                                              in the test data frame, preparatory to calculating rms error\n    testsdf$PRED<-testsdf$PRED-(mean(testsdf$PRED)-mean(testsdf$TOTCPROF))  #subtract out the difference\n    #btwn mean prediction and\n    #mean actual dep. variable\n    summary(testsdf)\n    # Now, calculate root-mean-square error of the predictions made by the neural net\n    testsdf$d2 <- (testsdf$TOTCPROF-testsdf$PRED)^2  # calculate the squared difference between the actual\n    #                                                                                  dependent variable and the prediction in test df\n    tail(testsdf)\n    rmstest <- sqrt(mean(testsdf$d2))    \n    rmstest                           # rmstest is the root-mean squared error\n    # for the test data set\n    # rms_test_results[n] <- rmstest\n    rms_test_results_m[l,n] <- rmstest\n    # test accuracy for both train and test\n    rms_train_pass_test_m[l,n] <-rms_train_results_m[l,n] < .02\n    rms_test_pass_test_m[l,n] <-rms_test_results_m[l,n] < 3*rms_train_results_m[l,n]\n    progress_bar$step()\n  }\n  \n}\n# print matrices of train and test results and give each proper row and column names\nrms_train_results_m\ncolnames(rms_train_results_m) <- c(1:total_nodes)\nrownames(rms_train_results_m) <- c(1:total_layers)\nrms_test_results_m\ncolnames(rms_test_results_m) <- c(1:total_nodes)\nrownames(rms_test_results_m) <- c(1:total_layers)\nrms_train_pass_test_m\nrms_test_pass_test_m\n# plot the RMSE to see how different combinations of layer/nodes reduce the error & compare against test data\nmatplot(t(rms_train_results_m),main='Training Data - RMSE vs Layer Hidden Neurons ', type = \"l\",xlab=\"Hidden neurons\",ylab='Train error - RMSE')\nlegend(\"topright\", c(\"1\", \"2\"), pch = 1, title = \"Layers\",col= 1:total_layers, ncol = total_layers)\nmatplot(t(rms_test_results_m),main='Test Data - RMSE vs Layer Hidden Neurons ', type = \"l\",xlab=\"Hidden neurons\",ylab='Test error - RMSE')\nlegend(\"topright\", c(\"1\", \"2\"), pch = 1, title = \"Layers\",col= 1:total_layers, ncol = total_layers)\n# Generate our winning NN layer/node (2 layers, 15 neurons) combination and generate a plot to display graph of NN\nnresults_final <- neuralnet(TOTCPROF ~ AGE + SEX + INCOME+ KIDHOME+ TEENHOME+ GOURMAGS+ WINEMAGS+ STYLMAGS+ HOUSMAGS+ SPRTMAGS+ TRAVMAGS+ CULTMAGS+ COMPMAGS+ FIRSTPUR+ LASTPUR+ LTV + PCTWEB+ PERCDR+ PERCSR+ PERCDW+ PERCSW+ PERCEX, trainsdf, hidden=c(15, 2), stepmax=80000, threshold=0.08)\nplot(nresults_final)   #take a look at a graph of the results\n# output the RMSE matrices to a flat file\nwrite.table(rms_train_results_m,file=\"rms_train_results_m.txt\") # keeps the rownames\nwrite.table(rms_test_results_m,file=\"rms_test_results_m.txt\") # keeps the rownames\n",
    "created" : 1517591080175.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "760890207",
    "id" : "62944D73",
    "lastKnownWriteTime" : 1516646900,
    "last_content_update" : 1516646900,
    "path" : "~/Dropbox/MRKT 845 Advanced Marketing Analytics/Project 1/project1_neural_nets_in_r/modeling_script.R",
    "project_path" : null,
    "properties" : {
    },
    "relative_order" : 3,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}